{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Martin-Sokolov-Sokolov/ESPMesh/blob/main/my.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 56,
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "ok": true,
              "status": 200,
              "status_text": ""
            }
          }
        },
        "id": "1YGIluwwsBtz",
        "outputId": "fd51736d-da51-4ab3-8969-6f8a3fe7f2ca"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-1da9a937-087b-4bbd-a961-cbcaa0d02227\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-1da9a937-087b-4bbd-a961-cbcaa0d02227\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving train.py to train.py\n"
          ]
        }
      ],
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "7pqSZuYfHBo-"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "\n",
        "startChar = 'ш'\n",
        "endChar = 'щ'\n",
        "unkChar = 'ь'\n",
        "padChar = 'ъ'\n",
        "\n",
        "import random\n",
        "\n",
        "corpusSplitString = ';)\\n'\n",
        "maxProgramLength = 10000\n",
        "symbolCountThreshold = 100\n",
        "\n",
        "def splitSentCorpus(fullSentCorpus, testFraction = 0.1):\n",
        "    random.seed(42)\n",
        "    random.shuffle(fullSentCorpus)\n",
        "    testCount = int(len(fullSentCorpus) * testFraction)\n",
        "    testSentCorpus = fullSentCorpus[:testCount]\n",
        "    trainSentCorpus = fullSentCorpus[testCount:]\n",
        "    return testSentCorpus, trainSentCorpus\n",
        "\n",
        "def getAlphabet(corpus):\n",
        "    symbols={}\n",
        "    for s in corpus:\n",
        "        for c in s:\n",
        "            if c in symbols: symbols[c] += 1\n",
        "            else: symbols[c]=1\n",
        "    return symbols\n",
        "\n",
        "def prepareData(corpusFileName, startChar, endChar, unkChar, padChar):\n",
        "    file = open(corpusFileName,'r', encoding=\"utf\")\n",
        "    poems = file.read().split(corpusSplitString)\n",
        "    symbols = getAlphabet(poems)\n",
        "    \n",
        "    assert startChar not in symbols and endChar not in symbols and unkChar not in symbols and padChar not in symbols\n",
        "    charset = [startChar,endChar,unkChar,padChar] + [c for c in sorted(symbols) if symbols[c] > symbolCountThreshold]\n",
        "    char2id = { c:i for i,c in enumerate(charset)}\n",
        "    \n",
        "    corpus = []\n",
        "    for i,s in enumerate(poems):\n",
        "        if len(s) > 0:\n",
        "            corpus.append( [startChar] + [ s[i] for i in range(min(len(s),maxProgramLength)) ] + [endChar] )\n",
        "\n",
        "    testCorpus, trainCorpus  = splitSentCorpus(corpus, testFraction = 0.01)\n",
        "    print('Corpus loading completed.')\n",
        "    return testCorpus, trainCorpus, char2id"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "CUksStFxbYl7"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "TSejR2nLHBpP"
      },
      "outputs": [],
      "source": [
        "#############################################################################\n",
        "### Търсене и извличане на информация. Приложение на дълбоко машинно обучение\n",
        "### Стоян Михов\n",
        "### Зимен семестър 2020/2021\n",
        "#############################################################################\n",
        "###\n",
        "### Домашно задание 3\n",
        "###\n",
        "#############################################################################\n",
        "\n",
        "import torch\n",
        "\n",
        "#################################################################\n",
        "####  LSTM с пакетиране на партида\n",
        "#################################################################\n",
        "\n",
        "class LSTMLanguageModelPack(torch.nn.Module):\n",
        "    def preparePaddedBatch(self, source):\n",
        "        device = next(self.parameters()).device\n",
        "        m = max(len(s) for s in source)\n",
        "        sents = [[self.word2ind.get(w,self.unkTokenIdx) for w in s] for s in source]\n",
        "        sents_padded = [ s+(m-len(s))*[self.padTokenIdx] for s in sents]\n",
        "        return torch.t(torch.tensor(sents_padded, dtype=torch.long, device=device))\n",
        "    \n",
        "    def save(self,fileName):\n",
        "        torch.save(self.state_dict(), fileName)\n",
        "        \n",
        "    def load(self,fileName):\n",
        "        self.load_state_dict(torch.load(fileName))\n",
        "\n",
        "    def __init__(self, embed_size, hidden_size, word2ind, unkToken, padToken, endToken, lstm_layers, dropout):\n",
        "        super(LSTMLanguageModelPack, self).__init__()\n",
        "        #############################################################################\n",
        "        ###  Тук следва да се имплементира инициализацията на обекта\n",
        "        ###  За целта може да копирате съответния метод от програмата за упр. 13\n",
        "        ###  като направите добавки за повече слоеве на РНН и dropout\n",
        "        #############################################################################\n",
        "        #### Начало на Вашия код.\n",
        "\n",
        "        self.word2ind = word2ind\n",
        "        self.unkTokenIdx = word2ind[unkToken]\n",
        "        self.padTokenIdx = word2ind[padToken]\n",
        "        self.endTokenIdx = word2ind[endToken]\n",
        "        \n",
        "        self.lstm = torch.nn.LSTM(embed_size, hidden_size, num_layers=lstm_layers)\n",
        "        self.dropout = torch.nn.Dropout(p=dropout, inplace=False)\n",
        "        self.embed = torch.nn.Embedding(len(word2ind), embed_size)\n",
        "        self.projection = torch.nn.Linear(hidden_size,len(word2ind))\n",
        "\n",
        "        #### Край на Вашия код\n",
        "        #############################################################################\n",
        "\n",
        "    def forward(self, source):\n",
        "        #############################################################################\n",
        "        ###  Тук следва да се имплементира forward метода на обекта\n",
        "        ###  За целта може да копирате съответния метод от програмата за упр. 13\n",
        "        ###  като направите добавка за dropout\n",
        "        #############################################################################\n",
        "        #### Начало на Вашия код.\n",
        "\n",
        "        X = self.preparePaddedBatch(source) # (w,s)\n",
        "        E = self.embed(X)\n",
        "        source_lengths = [len(s) for s in source]\n",
        "        outputPacked, _ = self.lstm(torch.nn.utils.rnn.pack_padded_sequence(E, source_lengths,enforce_sorted=False))\n",
        "        output,_ = torch.nn.utils.rnn.pad_packed_sequence(outputPacked)\n",
        "        D = self.dropout(output)\n",
        "        Z = self.projection(D.flatten(0, 1)) # (w*s,h)\n",
        "        return Z\n",
        "\n",
        "        #### Край на Вашия код\n",
        "        #############################################################################\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "45-FEpEEHBpX",
        "outputId": "ce42d454-4526-4dc1-fb5f-82d7c6c69006"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Corpus loading completed.\n",
            "Data prepared.\n"
          ]
        }
      ],
      "source": [
        "import pickle\n",
        "from parameters import *\n",
        "\n",
        "\n",
        "testCorpus, trainCorpus, char2id =  prepareData('corpusFunctions.txt', startChar, endChar, unkChar, padChar)\n",
        "pickle.dump(testCorpus, open(testDataFileName, 'wb'))\n",
        "pickle.dump(trainCorpus, open(trainDataFileName, 'wb'))\n",
        "pickle.dump(char2id, open(char2idFileName, 'wb'))\n",
        "print('Data prepared.')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 191,
      "metadata": {
        "id": "KJ7npAOnHBpZ"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "\n",
        "def generateCode(model, char2id, startSentence, limit=1000, temperature=1.):\n",
        "    # model е инстанция на обучен LSTMLanguageModelPack обект\n",
        "    # char2id е речник за символите, връщащ съответните индекси\n",
        "    # startSentence е началния низ стартиращ със символа за начало '{'\n",
        "    # limit е горна граница за дължината на поемата\n",
        "    # temperature е температурата за промяна на разпределението за следващ символ\n",
        "    \n",
        "    result = startSentence[0:]\n",
        "    softmax = torch.nn.Softmax()\n",
        "\n",
        "    #############################################################################\n",
        "    ###  Тук следва да се имплементира генерацията на текста\n",
        "    #############################################################################\n",
        "    #### Начало на Вашия код.\n",
        "\n",
        "    #rnd = np.random.choice(len(result), size=1)\n",
        "\n",
        "    result = softmax(model.forward(result))\n",
        "\n",
        "    sum = 0\n",
        "    for i in range(len(result)):\n",
        "      for j in range(107):\n",
        "        sum += torch.Tensor.item(result[i][j])\n",
        "\n",
        "    print(sum)\n",
        "    print(torch.Tensor.size(result))\n",
        "\n",
        "    #result = data[rnd]\n",
        "\n",
        "    #result = [char2id[i] for i in result]\n",
        "    \n",
        "    #### Край на Вашия код\n",
        "    #############################################################################\n",
        "\n",
        "    return result\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import train\n",
        "\n",
        "testCorpus = pickle.load(open(testDataFileName, 'rb'))\n",
        "char2id = pickle.load(open(char2idFileName, 'rb'))\n",
        "print('Model perplexity: ',train.perplexity(lm, testCorpus, batchSize))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rqeHCoE7nBwn",
        "outputId": "7a1a4753-036f-4aad-f77e-de0930db308b"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model perplexity:  4.40980754541837\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char2id = pickle.load(open(char2idFileName, 'rb'))\n",
        "lm = LSTMLanguageModelPack(char_emb_size, hid_size, char2id, unkChar, padChar, endChar, lstm_layers=lstm_layers, dropout=dropout).to(device)\n",
        "lm.load(modelFileName)"
      ],
      "metadata": {
        "id": "uRkkpOweope_"
      },
      "execution_count": 148,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "generateCode(lm, char2id, startChar, 1000, 1.0)"
      ],
      "metadata": {
        "id": "c6DbBJEJ6Z0r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9525c1b0-da3b-4d0a-9e49-fbe912c2d7c9"
      },
      "execution_count": 192,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.000000039105089\n",
            "torch.Size([1, 107])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:20: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1.1802e-05, 3.0190e-05, 1.2916e-03, 8.4763e-06, 5.5835e-06, 8.3459e-05,\n",
              "         5.5392e-04, 8.0156e-06, 4.0735e-04, 3.8413e-04, 1.0797e-04, 1.9476e-04,\n",
              "         7.7275e-05, 1.2647e-03, 2.9246e-03, 1.5336e-05, 2.5417e-05, 7.8793e-05,\n",
              "         6.0266e-05, 2.4226e-03, 6.5597e-04, 1.8432e-04, 4.4040e-04, 1.5358e-04,\n",
              "         1.1846e-04, 9.9550e-05, 6.6051e-05, 9.4099e-05, 6.0298e-05, 3.2746e-05,\n",
              "         2.9066e-05, 4.9850e-05, 8.5693e-03, 3.7776e-05, 4.5627e-05, 1.0682e-04,\n",
              "         2.4605e-04, 3.0884e-05, 6.4833e-04, 3.6123e-02, 6.6504e-03, 1.1244e-01,\n",
              "         3.6679e-02, 1.2075e-02, 6.4187e-02, 6.0786e-02, 7.9161e-03, 1.9561e-02,\n",
              "         1.9173e-03, 1.9583e-03, 1.9500e-02, 1.7521e-02, 1.1916e-02, 3.3685e-03,\n",
              "         2.9232e-02, 1.3378e-03, 2.8008e-01, 6.3184e-02, 1.1889e-01, 1.9421e-02,\n",
              "         8.1673e-03, 1.6678e-02, 2.3660e-03, 2.2726e-03, 7.1750e-04, 2.6895e-04,\n",
              "         3.6840e-04, 5.7256e-04, 8.9862e-05, 3.3731e-04, 6.0967e-04, 4.4285e-03,\n",
              "         2.5636e-04, 1.1766e-03, 6.2326e-04, 3.0051e-04, 9.0314e-04, 4.2549e-04,\n",
              "         3.8339e-04, 8.5523e-04, 1.2554e-04, 3.6533e-05, 3.6307e-04, 3.3902e-04,\n",
              "         2.8984e-04, 2.5258e-04, 4.5798e-04, 2.0022e-04, 1.6648e-03, 3.6654e-03,\n",
              "         7.5424e-04, 3.7014e-04, 6.9657e-04, 5.5186e-04, 1.7320e-04, 1.1805e-04,\n",
              "         1.9038e-05, 1.3818e-03, 9.8467e-05, 7.0183e-05, 6.3558e-05, 3.2039e-05,\n",
              "         1.9335e-05, 1.5554e-05, 2.0491e-05, 3.0135e-05, 2.3752e-05]],\n",
              "       grad_fn=<SoftmaxBackward0>)"
            ]
          },
          "metadata": {},
          "execution_count": 192
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "wQ64MFUV5-Mh"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "my.ipynb",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "91d86564ae35ab1a66c20cb3177b0ed504c2135135dc18004aec86b3eddd0eb3"
    },
    "kernelspec": {
      "display_name": "Python 3.7.11 64-bit ('tii': conda)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.11"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}